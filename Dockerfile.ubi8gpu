
FROM registry.access.redhat.com/ubi8-dev-preview/ubi:latest

MAINTAINER Subin Modeel <smodeel@redhat.com>

USER root

ENV BUILDER_VERSION 1.0

LABEL io.k8s.description="S2I builder for Tensorflow binaries." \
      io.k8s.display-name="Tensorflow BUILD" \
      io.openshift.expose-services="8080:http" \
      io.openshift.tags="builder,python,tf-build" \
      io.openshift.s2i.scripts-url="image:///usr/libexec/s2i"

ENV LANG en_US.UTF-8
ENV LANGUAGE en_US.UTF-8
ENV LC_COLLATE C
ENV LC_CTYPE en_US.UTF-8 

ENV \
    # Path to be used in other layers to place s2i scripts into
    STI_SCRIPTS_PATH=/usr/libexec/s2i \
    APP_ROOT=/opt/app-root \
    # The $HOME is not set by default, but some applications needs this variable
    HOME=/opt/app-root/src \
    PATH=/opt/app-root/src/bin:/opt/app-root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin

# Add default user
RUN \
  mkdir -p /opt/app-root/src/bin && \
  useradd -u 1001 -r -g 0 -d ${HOME} -s /sbin/nologin \
      -c "Default Application User" default && \
  chown -R 1001:0 ${APP_ROOT}

############################################
## taken from base
## https://hub.docker.com/r/nvidia/cuda/
############################################

RUN NVIDIA_GPGKEY_SUM=d1be581509378368edeec8c1eb2958702feedf3bc3d17011adbf24efacce4ab5 && \
    curl -fsSL https://developer.download.nvidia.com/compute/cuda/repos/rhel7/x86_64/7fa2af80.pub | sed '/^Version/d' > /etc/pki/rpm-gpg/RPM-GPG-KEY-NVIDIA && \
    echo "$NVIDIA_GPGKEY_SUM  /etc/pki/rpm-gpg/RPM-GPG-KEY-NVIDIA" | sha256sum -c --strict -

COPY cuda.repo /etc/yum.repos.d/cuda.repo

ENV CUDA_VERSION 9.2.148

ENV CUDA_PKG_VERSION 9-2-$CUDA_VERSION-1
RUN dnf install -y \
        cuda-cudart-$CUDA_PKG_VERSION && \
    ln -s cuda-9.2 /usr/local/cuda && \
    rm -rf /var/cache/yum/*

##------------------------
## taken from devel
##------------------------
ENV LIBRARY_PATH /usr/local/cuda/lib64/stubs
##========================
##------------------------
## taken from runtime
##------------------------
ENV CUDNN_VERSION 7.1.4.18
LABEL com.nvidia.cudnn.version="${CUDNN_VERSION}"
##========================

# nvidia-docker 1.0
LABEL com.nvidia.volumes.needed="nvidia_driver"
LABEL com.nvidia.cuda.version="${CUDA_VERSION}"

RUN echo "/usr/local/nvidia/lib" >> /etc/ld.so.conf.d/nvidia.conf && \
    echo "/usr/local/nvidia/lib64" >> /etc/ld.so.conf.d/nvidia.conf

ENV PATH /usr/local/nvidia/bin:/usr/local/cuda/bin:${PATH}
ENV LD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64

# nvidia-container-runtime
ENV NVIDIA_VISIBLE_DEVICES all
ENV NVIDIA_DRIVER_CAPABILITIES compute,utility
ENV NVIDIA_REQUIRE_CUDA "cuda>=9.2"

##------------------------
## taken from tensorflow
##------------------------
ENV LD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH
ENV TF_CUDA_COMPUTE_CAPABILITIES=3.5,5.2,6.0,6.1,7.0
ENV TF_CUDA_VERSION=9.2
ENV TF_CUDNN_VERSION=7

# NCCL 2.x
ENV TF_NCCL_VERSION=2
##========================
############################################

# DONOT change the location of the following ENVs
ENV CUDA_HOME="/usr/local/cuda" 
ENV CUDA_PATH="/usr/local/cuda" 
ENV PATH="/usr/local/cuda/bin${PATH:+:${PATH}}" 
ENV LD_LIBRARY_PATH="/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}"; 
ENV LD_LIBRARY_PATH="/usr/local/cuda/lib64/stubs/:$LD_LIBRARY_PATH"


# DONOT uncomment. uncomment for dev.
ARG BAZEL_VERSION=0.20.0
ARG PYTHON_VERSION=3.6
ENV BAZEL_VERSION=$BAZEL_VERSION
ENV PYTHON_VERSION=$PYTHON_VERSION

# Not essential, but wise to set the lang
# Note: Users with other languages should set this in their derivative image
ENV LANGUAGE en_US.UTF-8
ENV LANG en_US.UTF-8
ENV LC_ALL=""
ENV PYTHONIOENCODING UTF-8
ENV NB_USER=default
ENV NB_UID=1001
ENV PYTHON_BIN_PATH=/usr/bin/python
ENV TINI_VERSION=v0.18.0

## Bazel
ENV PYTHON_LIB_PATH=/usr/lib64/python$PYTHON_VERSION/site-packages
ENV LD_LIBRARY_PATH="/usr/local/lib${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}";
ENV BAZELRC /root/.bazelrc
#### ENV BAZEL_VERSION = DONOT UNCOMMENT
################################################
## Tensorflow ./configure options for Bazel
################################################
ENV PYTHON_BIN_PATH=/usr/bin/python$PYTHON_VERSION
ENV CC_OPT_FLAGS -march=native
ENV TF_NEED_JEMALLOC 1
ENV TF_NEED_GCP 0
ENV TF_NEED_VERBS 0
ENV TF_NEED_HDFS 0
ENV TF_ENABLE_XLA 0
ENV TF_NEED_OPENCL 0
ENV TF_NEED_CUDA 0
ENV TF_NEED_MPI 0
ENV TF_NEED_GDR 0
ENV TF_NEED_S3 0
ENV TF_NEED_KAFKA 0
ENV TF_NEED_OPENCL_SYCL 0
ENV TF_DOWNLOAD_CLANG 0
ENV TF_SET_ANDROID_WORKSPACE 0
ENV PATH /usr/local/bin:$PATH:/home/default/.local/bin
ENV JAVA_HOME /usr/lib/jvm/java-1.8.0-openjdk-1.8.0*

RUN echo 'PS1="\u@\h:\w\\$ \[$(tput sgr0)\]"' >> /root/.bashrc \
    && dnf install -y python36 python3-devel python3-pip \
    && ln -s /usr/bin/python3.6 /usr/bin/python \
    && ln -s /usr/bin/pip3.6 /usr/bin/pip \
    && dnf install -y tar which git curl wget java-headless bzip2 gnupg2 sqlite kmod \
    && echo "-----IMAGE_TEST--------" \
    && ls -l /usr/bin/python \
    && echo "which_python="`which python` \
    && echo "link_which_python=`ls -l $(which python) | awk '{print  $9 $10 $11}'`" \
    && echo "link_bin_python=`ls -l /usr/bin/python |awk '{print  $9 $10 $11}'`" \
    && echo "which_pip="`which pip` \
    && echo "which_pip_site="`pip --version |awk '{print $4}'` \
    && echo "link_which_pip=`ls -l $(which pip) | awk '{print  $9 $10 $11}'`" \
    && echo "PATH=$PATH" \
    && echo "PYTHON_VERSION=$PYTHON_VERSION" \
    && echo "LD_LIBRARY_PATH=$LD_LIBRARY_PATH" \
    && echo "PYTHON_LIB_PATH=$PYTHON_LIB_PATH" \ 
    && echo "-----IMAGE_TEST--------" \
    && chgrp -R root /opt \
    && chmod -R a+rwx /opt \
    && chmod a+rw /etc/passwd \
    && dnf install -y vim gcc gcc-c++ glibc-devel openssl-devel gpg \
    && dnf install -y findutils dmidecode procps \
    && dnf install -y make automake autoconf xz zip unzip libtool binutils \
    && dnf install -y freetype-devel zlib-devel \
    && dnf install -y libxml2 libxml2-devel libxslt libxslt-devel gzip \
    && dnf install -y java-1.8.0-openjdk java-1.8.0-openjdk-devel patch gdb file pciutils cmake \
#########################
## taken from runtime
#########################
    && dnf install -y cuda-libraries-$CUDA_PKG_VERSION cuda-nvtx-$CUDA_PKG_VERSION \
#########################
## taken from devel
#########################
    && dnf install -y cuda-libraries-dev-$CUDA_PKG_VERSION cuda-nvml-dev-$CUDA_PKG_VERSION cuda-minimal-build-$CUDA_PKG_VERSION  cuda-command-line-tools-$CUDA_PKG_VERSION \
    && rm -rf /var/cache/yum/* \
#########################
## taken from runtime
#########################
    && CUDNN_DOWNLOAD_SUM=f875340f812b942408098e4c9807cb4f8bdaea0db7c48613acece10c7c827101 \
    && curl -fsSL http://developer.download.nvidia.com/compute/redist/cudnn/v7.1.4/cudnn-9.2-linux-x64-v7.1.tgz -O \
    && echo "$CUDNN_DOWNLOAD_SUM  cudnn-9.2-linux-x64-v7.1.tgz" | sha256sum -c - \
    && mkdir -p /usr/local/cudnn \
    && tar --no-same-owner -xzf cudnn-9.2-linux-x64-v7.1.tgz -C /usr/local/cudnn --strip-components 1 \
    && ln -s /usr/local/cudnn/include/cudnn.h /usr/local/cuda/include/cudnn.h \
    && cp /usr/local/cudnn/lib64/* /usr/local/cuda/lib64 \
    && rm cudnn-9.2-linux-x64-v7.1.tgz \
    && ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1 \
    && ldconfig \
#########################
## taken from tf
#########################
## https://tech.amikelive.com/node-735/how-to-install-nvidia-collective-communications-library-nccl-2-for-tensorflow-on-ubuntu-16-04/
    && mkdir -p /usr/local/nccl-2.2 \
    && wget http://file.rdu.redhat.com/~smodeel/nccl_2.2.13-1+cuda9.2_x86_64.txz -P /usr/local/nccl-2.2/ \
    && unxz /usr/local/nccl-2.2/nccl_2.2.13-1+cuda9.2_x86_64.txz \
    && tar -xvf /usr/local/nccl-2.2/nccl_2.2.13-1+cuda9.2_x86_64.tar -C /usr/local/nccl-2.2/ --strip-components 1 \
	&& export LD_LIBRARY_PATH="/usr/local/nccl-2.2:/usr/local/cuda-9.2${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}" \
    && ln -s /usr/local/nccl-2.2/include/nccl.h /usr/include/nccl.h \
    && ln -s /usr/local/nccl-2.2/include/nccl.h /usr/local/cuda/include/nccl.h \
## Link NCCL libray and header where the build script expects them. \
	&& mkdir -p /usr/local/cuda-9.2/lib  \
    && ln -s /usr/lib/nccl-2.2/lib/libnccl.so.2 /usr/local/cuda/lib/libnccl.so.2 \
#########################
    && mkdir -p /home/$NB_USER/.ssh \
    && echo 'alias ll="ls -l"' >> /home/$NB_USER/.bashrc \
    && ssh-keyscan pagure.io >> /home/$NB_USER/.ssh/known_hosts \
    && wget -q https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini -P /tmp \
    && wget -q https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini.asc -P /tmp \
    && cd /tmp \
    && mv /tmp/tini /usr/local/bin/tini \
    && chmod +x /usr/local/bin/tini \
    && chown -R 1001:1001 /opt/app-root \
    && chgrp -R root /opt/app-root \
    && chmod -R ug+rwx /opt/app-root \
    && echo "startup --batch" >>/etc/.bazelrc \
    && echo "startup --batch" >>/root/.bazelrc \
    && echo "build --spawn_strategy=standalone --genrule_strategy=standalone" >>/etc/.bazelrc \
    && echo "build --spawn_strategy=standalone --genrule_strategy=standalone" >>/root/.bazelrc


#https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/install/.bazelrc
# Running bazel inside a `docker build` command causes trouble, cf:
#   https://github.com/bazelbuild/bazel/issues/134
# The easiest solution is to set up a bazelrc file forcing --batch.
# Similarly, we need to workaround sandboxing issues:
#   https://github.com/bazelbuild/bazel/issues/418
#

# A cloned repo is found under serving folder
#Size of bazel-$BAZEL_VERSION-installer-linux-x86_64.sh is 200MB+
# downloaded file is available under bazel folder



# No yum commands here
# removed python to fix numpy issue
RUN mkdir -p /tf \
    && pip install --no-cache-dir -U setuptools \
    && pip install --no-cache-dir enum34 futures mock numpy six pixiedust pillow pyyaml \
    && mkdir -p /tf/tools \
    && cd /tf/tools \
    && wget -q https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \
    && ls -l /tf/tools \
    && chmod +x bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \
    && ./bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \
    && bazel \
    && usermod -g root $NB_USER \
    && mkdir -p /workspace \
    && chown $NB_UID:root /workspace \
    && chmod 1777 /workspace \
    && mkdir -p /home/$NB_USER \
    && chown -R $NB_UID:root /home/$NB_USER \
    && chmod g+rwX,o+rX -R /home/$NB_USER

COPY ./s2i/bin/ /usr/libexec/s2i
ADD test/ /tmp/test/
ADD entrypoint /entrypoint
RUN chmod +x /entrypoint
ADD build_tools /build_tools

EXPOSE 8080

ENV HOME /home/$NB_USER
USER 1001
# Make the default PWD somewhere that the user can write. This is
# useful when connecting with 'oc run' and starting a 'spark-shell',
# which will likely try to create files and directories in PWD and
# error out if it cannot.

WORKDIR /workspace

ENTRYPOINT ["/entrypoint"]

# TODO: Set the default CMD for the image
CMD ["/usr/libexec/s2i/usage"]

